# IEEE-CIS Fraud Detection

მოცემულ kaggle-ს კონკურსში, მოცემული გვქონდა დიდი მონაცემთა სიმრავლე, რომელის გამოყენებით უნდა გვეწინასწარმეტყველა, იყო თუ არა, რაიმე კონკრეტული მონაცემი fraud (თაღლითური). მეტრიკა, რომლის საშუალებითაც იზომება მოდელი, მოცემულ კონკურსში არის roc-auc. ასევე, მონაცემებს გააჩნიათ დიდი დისბალანსი, რაც იწვევს იმას, რომ roc-auc ისედაც მაღალია.

ამ პროექტში მე გავტესტე, რამდენიმე მოდელი და რამდენიმე feature cleaning/engineering ტექნიკება. თითეულ მათგანზე, უფრო დეტალურად შემდეგში ვისაუბრებ.

---

# რეპოზიტორიის სტრუქტურა

- `notebooks/` — ამ ფოლდერში, არის ძირითადი მოდელების ტრენინგ კოდები, ასევე საუკეთესო მონაცემის დალოგვისა და ზოგადი მონაცემთა ანალიზის notebook.
- `README.md` — ფაილი, სადაც ჩვენი მიდგომები, მოკლედ არის შეჯამებული.

---

# Feature Engineering

## Nan მნიშვნელობების დამუშავება

პირველ რიგში გადავაგდე, ყველა feature, რომელშიც 0.8-ზე მეტი უცნობი მნიშვნელობა იყო. ეს ისევე, როგორც ბევრი სხვა პარამეტრი, ავარჩიე მონაცემებზე დაკვირვებით (შეგიძლიათ ნახოთ eda-data-analysis.ipyn). თუმცა, მაინც გავტესტე 0.7 და ამ უკანასკნელმა, როგორც მოსალოდნელი იყო, ბევრად უარესი შედეგი მომცა. 

Nan მნიშვნელობის დამუშავებისთვის, გამოვიყენე მსგავსი მეთოდი, ყველა მოდელისთვის საერთო. ეს მოთოდი, ქროს ვალიდაციით ავარჩიე და თითქმის ყველგან საუკეთესო შედეგი დადო. კერძოდ, თუ მქონდა numerical feature-ები,გამოვიყენე მედიანით შევავსების მეთოდი, ხოლო categorical feature-ებისთვის გამოვიყენე რაიმე მუდმივი ლეიბლით შევდების მეთოდი.

## კატეგორიული ცვლადების რიცხვითში გადაყვანა

ასეთ, შემთხვევაში გამოვიყენეთ, რამდენიმე მიდგომა. ძირითადი, მიდგომა იყო one-hot encoding + woe, რაც გულისხმობს, რომ თუ განსხვავებული მონაცემების რაოდენობა სამზე დიდი იყო, რომელიმე feature-ში, მაშინ მასსზე woe-encoding-ს გამოვიყენებდი, წინააღმდეგ შემთხვევაში კი one-hot-ს. ეს პარამეტრი, ქროს ვალიდაციით არ გადამირჩევია, რადგან ძალიან დიდ დროს ანდომებდა. 3 ან 4 ლოგიკური მოსჩანდა, იმის გათვალისწინებით, რომ მონაცებთა სიმრავლე ისედაც დიდი იყო, და one-hot-ს საშუალებით მისი გადიდება, სხვა პროცესებს ბევრად გაანელებდა.

ასევე, მეორე მიდგომა, რომელიც გამოვიყენე (ძირითადა Random Forest მოდელის ტრენინგისას) იყო frequency-encoding, რაც გულისხმობს, რომ თითოეულ label-ს ვუსაბამებთ მის სიხშირეს. ეს მიგომა, ლოგიკურია ხის მოდელისთვის, რადგან თითოეულ კატეგორიას ვაძლევთ რაღაც ტიპის ordering(დალაგებას). ასეთ, შემთხვევაში მოდელის განარჩევს, იმ label-იან დატას, რომელიც უფრო იშვიათია, იმ label-იანი დატასგან, რომელიც ხშირად გვხვდება (როდესაც, თრეშჰოლდს ამოირჩევს Random Forest).

# Feature Selection

## გამოყენებული მიდგომები

აქ  ვცადე რამდენიმე მიდგომა. პირველი მიდგომა, რომელიც ყველა მოდელზე ვცადე იყო RFE, თუმცა ვერ მოვახერე ამ იარაღის გამოყენება მაღალი პარამეტრებით RandomForest და LogisticRegression მოდელებზე, რადგან დიდ დროს ანდომებდა. XGboost-ზე კი კარგად იმუშავა.

ამის, გამო რამდენიმე FeatureSelection ტექნიკები, როგორიცაა, Corelation Filter და Variation Filter გამოვიყენე. გავტესტ corelation_threshold = 0.8 და 0.9, და 0.9-მ უკეთესი შედეგი აჩვენა. ასევე, varience_threshold=0.01-მა ყველაზე კარგი შედეგი აჩვენა. 

RandomForest-სთვის გამოვიყენე ორი დამატებითი ტექნიკა, როგორიცაა SHAP და ზოგადად feature importance. ჯერ, გადავყარე ყველა რომელიც უმნიშვნელო იყო RandomForest-სთვის. ამ მიდგომით გატესტილმა RandomForest-მა ყველაზე კარგი შედეგი აჩვენა და გამოთვლის დროც საგრძნობლად შეამცირა.

## შეფასება

მოდელის შესაფასებლად უბრალოდ, გავყავი სიმრავლე ორ ნაწილად X_train, y_train და X_valid, y_valid. მოდელის საბოლოო ქულა დამოკიდებული იყო მის შედეგზე X_valid, y_valid სიმრავლეებზე, კერძოდ roc_auc ქულაზე.

# Training

## ტესტირებული მოდელები

- Logistic Regression
- Random Forest Classifier
- XGBoost Classifier



## Logistic Regresion

გამოვიყენე ზემოთ ნახსენები, feature-engineering ტექნიკები (სხვადასხვა პარამეტრებით). გამოვიყენე RFE, თუმცა მეხსიერებისა და დროის პრობლემების გამო, მკაცრად გავფილტრე მონაცემები. კერძოდ, RFE გავუშვი შემდეგი პარამეტრებით step = 0.1 , n_features=100. ძირითადად ვიმუშავე saga solver-ით. საერთო ჯამში, ძალიან მალევე მოდელის ტრენინგისას, აშკარა გახდა რომ Logistic Regresion, ძალიან ცუდი მოდელია ამ ამოცანისთვის, რადგან ტრენინგმა დიდი ხანი მოანდობა, ხოლო roc_auc შედეგი ძალიან ცუდი იყო, ისევე როგორც ტრენინგ სეტზე, ასევე ვალიდაციის სეტზე. ამიტომაც, ამ მოდელზე ექსპერიმენტები აღარ გავაგრძელე. 

მიზეზი, იმისა, თუ რატომ არ ვარგა Logistic Regresion, ძალიან მარტივია. უბრალოდ, არ არის საკმარისად კომპლექსური მოდელი მონაცემების ასაღწერად.

## Random Forest

როგორც უკვე აღვნიშნე, თავდაპირველად Random Forest-სთვის გამოვიყენე FrequencyEncoder და ასევე კორელაციისა და ვარიაციის ფილტერები, პარამეტრები რამდენიმე ვარიანტის მოსინჯვით შევარჩიე, შედარებით მარტივი random forest-ის გამოყენებით.

დავატრენინგე სამი ტიპის მოდელი. კერძოდ, ჰიპერპარამეტრების, როგორიცაა n_estimator, max_depth ..., მნიშვნელობეი სხვადასხხვა მოდელისთვის იყო მცირე, საშუალო და დიდი (დავარქვათ მოდელებს, rf_low, rf_mediul, rf_high). ქვემოთ, ცხრილში მოცემულია შედეგები:

- rfe_low: train_roc = 0.91, valid_roc = 0.90
- rfe_medium: train_roc = 1, valid_roc = 0.94
- rfe_high: train_roc = 1, valid_roc = 0.94

როგორც ჩანს, დიდი სხვაობა არაა rfe_medium მოდელსა და rfe_high მოდელს შორის. ამიტომ, შემდეგი ტრენინგებისთვის rfe_medium გამოვიყენე. ასევე, შევნიშნოთ, რომ train_roc = 1 რაც პრობლემატური შეიძლება იყოს, რადგან გვაქვს overfitting. 

ასევე, შევცვალე feature selection მიდგომა და გამოვიყენე მხოლოდ SHAP feature selector. მსგავსი მიდგომით დატრენინგებულმა rfe_medium- შემდეგი შედეგი აჩვენა: 

- rfe_shap: train_roc = 1, valid_roc = 0.94

ანუ თითქმის იგივე შედეგი.

## XGboost

ეს მოდელი როგორც მოსალოდნელი იყო, ყველაზე შედეგიანი აღმოჩნდა და შევეცდები უფრო დეტალურად აღვწერო მუშაობის პროცესი.

თავდაპირველად გამოვიყენე იგივე feature engineering მეთოდები (იგივე პარამეტრები და ა.შ), რაც წინა მოდელებში. კერძოდ შემდეგი მეთოდები:

- გადავაგდე ისეთი feature-ები როლებშიც 0.8-ზე მეტი უცნობი (NaN) მნიშვნელობები იყო.
- გამოვიყენე one-hot/woe, როგორც ზემოთ არის აღწერილი.
- გამოვიყენე RFE-s მიერ დატოვებული feature-ები, რომელთა რაოდენობა 100-ს ტოლი იყო.

ასეთი preprocess-ით გავტესტე რამდენიმე მოდელი, ქროსვალიდაციით გადავარჩიე პარამეტრების და მივიღე შემდეგი შედეგები:

- **max_depth** = 25
- **min_child_weight** = 1
- **roc_auc_train** = .99
- **roc_auc_valid** = .95

თუმცა, overfitting-სგან თავის ასაცილებლად გადავწყვიტე რეგულაციის პარამეტრების გადარჩევას, და შესაბამისად მივიღე ახალი მოდელი

- **max_depth** = 10
- **min_child_weight** = 1
- **reg_alpha** = 0
- **reg_lambda** = 10
- **roc_auc_train** = 1
- **roc_auc_valid** = .96

ამ მოდელს შედარებით მაღალი ვარიაცია აქვს. შესაძლოა ჰქონდეს overfitting-ს პრობლემაც.

აქვე, აღვნიშნავ, რომ overfitting-ს პრობლემის მოგვარების მიზნით დავატრენინგე მოდელები, რომლებსაც რეგულაზიიც პარამეტრები საგრძნობლად გავუზარდე ხელით. კერძოდ, reg_alpha=reg_lambda=50, ამ მოდელებმა ოდნავ უარესი შედეგი აჩვენეს ვიდრე, ზემოთ აღნიშნულმა მოდელებმა, ვალიდაციის ტესტზე, თუმცა რაღაც მხრივ უკეთესი მოდელებიც არიან, კერძოდ ნაკლები ვარიაცია (თუმცა მეტი ბაიესი) აქვთ და ნაკლებად აქვთ overfitting-ის პრობლემა. ეს იმაშიც გამოიხატება, რომ ნაკლებად იზეპირებენ თრეინ სეტს, roc_auc_train ბევრი სხვა მოდელისგან განსხვავებით შედარებით დაბალი აქვთ(კერძოდ 0.97), რაც რაღაც მხრივ კარგია. ეს მოდელები mlflow-ზე დავლოგე შემდეგი ფორმატის სახელებით: "name_d". მათ შორის ყველაზე საუკეთესო იყო drfe_9_d, რომელიც ქვემოთ აღწერილი drfe_9 მოდელის ალტერნატიული ვერსიაა, უბრალოდ მაღალი რეგულაციის პარამეტრებით.

ასევე, გავტესტე მოდელი ყველანაირი feature selection მეთოდების გარეშე, რამაც უკეთესი შედეგი დადო. ეს კი იმას მიანიშნებდა, რომ feature selection მეთოდი არ მიესადაგებოდა, xgboost-ს ამიტომ გადავწყვიტე ეს უკანასკნელი შემეცვალა.

ამიტომ ახალი RFE ძებნები გავუშვი უკვე ახალ პარამეტრებიან xgboost-ზე, ასევე გავტესტე კორელაციის ფილტერები სხვადასხვა თრეშჰოლდებით. საერთო, ჯამში მივიღე ახალი feature-ების სიმრავლე (რომლების შეგიძლიათ იხილოთ mlflow-ზე). შემდეგ, კიდევ ერთხელ, ხელახლა, ქროს ვალიდაციით გადავარჩიე მოდელის ჰიპერპარამეტრები და მივიღე შემდეგი მოდელი (სახელად drfe_9):

- **max_depth** = 25
- **min_child_weight** = 1
- **reg_alpha** = 0
- **reg_lambda** = 10
- **corelation_threashold** = 0.9
- **remained_features** - see on the mlflow
- **roc_auc_train** = 1
- **roc_auc_valid** = .97

ბოლოს, კი გავტესტე დატასეტის დაბალანსირების მიდგომა (რადგან ძალიან დაუბალანსებელი დატასეტი გვაქვს), ზემოთ მიღებულ მოდელზე. ამისთვის გამოვიყენე, ჩაშენებული SMOTE კლასი. ამ მოდელმა (სახელად drfe_balanced), პერფორმანსი მცირედით გააუმჯობესა.

## საბოლოო მოდელის შერჩევა

ცხადია, მოდელი ავირჩიე xgboost მოდელებისგან. არჩევანი მქონდა სამ მოდელს, შორის. კერძოდ: drfe_9_d, drfe_9 და drfe_balanced, მოდელებს შორის. მიუხედავათ, იმისა, რომ მე ყველაზე მეტად drfe_9_d მომეწონა, რადგან ჩემს მიერ გატესტილ მოდელებს შორის ყველაზე ნაკლებად აქვს overfitting-ის პრობლემა, კაგლის კონკურსისთვის, ჩავთვალე, რომ drfe_balanced-ს საუკეთესო შედეგი ექნებოდა, მხოლოდ იმიტომ, რომ ყველაზე კარგ შედეგს დებდა ვალიდაციის სეტზე. ამიტომაც, ეს მოდელი ავირჩიე.

---

# MLflow Tracking

## MLflow ექსპერიმენტის ბმული

[MLflow Experiment](https://dagshub.com/zhorzholianimate/IEEE-CIS-Fraud-Detection.mlflow/)

## ჩაწერილი მეტრიკები

ROC-AUC

## საუკეთესო მოდელის შედეგები

- **Validation ROC AUC**:  0.9684...
- **Test ROC AUC**: 0.9197.../0.895...
